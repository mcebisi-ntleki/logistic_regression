{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-03-16T11:26:04.855263Z\",\"iopub.execute_input\":\"2023-03-16T11:26:04.855695Z\",\"iopub.status.idle\":\"2023-03-16T11:26:04.863191Z\",\"shell.execute_reply.started\":\"2023-03-16T11:26:04.855661Z\",\"shell.execute_reply\":\"2023-03-16T11:26:04.861721Z\"}}\n#Packages required \n\nimport numpy as np # linear algebra\nimport matplotlib.pyplot as plt\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler #for robust feature scaling\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score, roc_curve, auc\nfrom scipy import stats # Hypthesis testing \nimport seaborn as sns\n\n\n# %% [markdown]\n# Note1\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-03-16T11:28:33.167478Z\",\"iopub.execute_input\":\"2023-03-16T11:28:33.168422Z\",\"iopub.status.idle\":\"2023-03-16T11:28:33.416387Z\",\"shell.execute_reply.started\":\"2023-03-16T11:28:33.168376Z\",\"shell.execute_reply\":\"2023-03-16T11:28:33.415594Z\"}}\ndata_df = pd.read_csv(\"/kaggle/input/breast-cancer-wisconsin/data.csv\")\n\ndata_df.head().T\n#data_df.info()\ndata_df.diagnosis = data_df.diagnosis.apply(lambda x: 1 if x == 'M' else 0)\n#data_df.info()\ndata_df.shape\ndata_df.columns\nprint(data_df.isnull().sum().sum())\ndata_df = data_df.dropna(axis = 1)\n\n\n\nB, M = data_df.diagnosis.value_counts()\nxtickmarks = ['B', 'M']\n\nprint(f'Number of Malignant tumours: {M}')\nprint(f'Number of Benign tumours   : {B}')\n\ndef createCountplot():\n    fig = plt.figure(figsize = (8, 6))\n    ax = fig.add_subplot()\n\n    sns.set_theme(style = 'whitegrid')\n\n    sns.countplot(data = data_df, \n              x = data_df.diagnosis, \n              label = 'Count',\n              lw = 4,\n              ec = 'black').set(title = 'A count of benign and malignant tumours',\n                                  xlabel = 'Diagnosis',\n                                  ylabel = 'Count')\n\n    ax.set_xticklabels(xtickmarks)\n    plt.show()\n\ncreateCountplot()\n\nvariables_to_omit = ['id', 'diagnosis']\ninput_data = data_df.drop(variables_to_omit, axis = 1)\nr, c = input_data.shape\nprint(f'Sample size                    : {r}')\nprint(f'Number of independent variables: {c}')\n\n\n# %% [markdown]\n# Histograms\n# \n# \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-03-13T15:39:24.206466Z\",\"iopub.execute_input\":\"2023-03-13T15:39:24.206933Z\",\"iopub.status.idle\":\"2023-03-13T15:39:25.376340Z\",\"shell.execute_reply.started\":\"2023-03-13T15:39:24.206898Z\",\"shell.execute_reply\":\"2023-03-13T15:39:25.374787Z\"}}\nMalignant = data_df[data_df['diagnosis'] == 1]\nBenign = data_df[data_df['diagnosis'] == 0]\nworst_mean_se = ['area_worst', 'fractal_dimension_mean', 'radius_se']\n\ndef makeHistogram(features):\n    for feature in features:\n        if not type(feature) is str:\n            raise TypeError('Only strings are permitted')\n            \n    fig = plt.figure(figsize = (10, 8))\n    for i, feature in enumerate(features):\n        ax = fig.add_subplot(1, 3, i + 1)  \n        sns.histplot(Malignant[feature], \n                   bins = bins, \n                   color = 'red', \n                   label = 'Malignant',\n                   kde = True)\n        sns.histplot(Benign[feature], \n                   bins = bins, \n                   color = 'green', \n                   label = 'Benign',\n                   kde = True)\n        plt.title(str(' Distribution of  ') + str(feature.replace('_', ' ').capitalize()))\n        plt.xlabel(str(feature.replace('_', ' ').capitalize()))\n        plt.ylabel('Density function')\n        plt.legend(loc = 'upper right')\n        ax.grid(False)\n    \n    plt.tight_layout()\n    plt.show()\n\nbins = 'fd' #Freedman and Diaconis \n\nmakeHistogram(worst_mean_se)\n\n# %% [markdown]\n# **Heatmaps** provide an informative way to depict two-dimensional data of the kind we have before us. A *heatmap* is an image in which the colour of each pixel is determined by the corresponding value in the array of data. \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-03-13T15:39:31.176011Z\",\"iopub.execute_input\":\"2023-03-13T15:39:31.176496Z\",\"iopub.status.idle\":\"2023-03-13T15:39:33.949052Z\",\"shell.execute_reply.started\":\"2023-03-13T15:39:31.176460Z\",\"shell.execute_reply\":\"2023-03-13T15:39:33.947885Z\"}}\ndef createHeatmap():\n    sns.set_theme(style ='white')\n    #Generate a mask for the upper triangular matrix\n    mask = np.triu(input_data.corr(), k = 0)\n\n    fig = plt.figure(figsize = (18, 18))\n    ax = fig.add_subplot()\n\n    # Generate a custom diverging palette of colours\n    cmap = sns.diverging_palette(230, 20, as_cmap = True)\n\n    sns.heatmap(data = input_data.corr(), \n                annot = True, \n                linewidths = 0.5, \n                fmt = '.1f',\n                ax = ax, \n                mask = mask,\n                cmap = cmap)\n\n    plt.title('A correlation heatmap of the features', fontsize = 20)\n    plt.show()\n\ncreateHeatmap()\n\n# %% [markdown]\n# More plots\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-03-13T15:39:40.704942Z\",\"iopub.execute_input\":\"2023-03-13T15:39:40.705373Z\",\"iopub.status.idle\":\"2023-03-13T15:39:41.328918Z\",\"shell.execute_reply.started\":\"2023-03-13T15:39:40.705336Z\",\"shell.execute_reply\":\"2023-03-13T15:39:41.327639Z\"}}\n# Create box and whiskers plot for texture mean by diagnosis of tumour\nDiagnosis = 'diagnosis'\n\ndef makeBoxplot(features):\n    fig = plt.figure(figsize = (8, 12))\n    for i, feature in enumerate(features):\n        ax = fig.add_subplot(2, 2, i + 1)\n        sns.boxplot(x = Diagnosis, \n                   y = feature, \n                   data = data_df, \n                   showfliers = True)\n        plt.title(str(feature.replace('_', ' ').capitalize()))\n        ax.set_xticklabels(xtickmarks)\n        ax.set_xlabel(Diagnosis.capitalize())\n        ax.set_ylabel(str(feature.replace('_', ' ').capitalize()))\n        ax.grid(False)\n    \n    fig.tight_layout()\n    plt.show()\n\nmakeBoxplot(worst_mean_se)\n\n\n\n# %% [markdown]\n# Logistic regression plots\n\n# %% [markdown]\n# Some more box and whiskers plots\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-03-13T15:39:56.192303Z\",\"iopub.execute_input\":\"2023-03-13T15:39:56.193807Z\",\"iopub.status.idle\":\"2023-03-13T15:40:10.303454Z\",\"shell.execute_reply.started\":\"2023-03-13T15:39:56.193745Z\",\"shell.execute_reply\":\"2023-03-13T15:40:10.301789Z\"}}\ndef logistic_regression_plot(features):\n    fig = plt.figure(figsize = (11, 5))\n    for i, feature in enumerate(features):\n        ax = fig.add_subplot(1, 3, i + 1)\n        sns.regplot(data = data_df,\n                    x = feature, \n                    y = Diagnosis, \n                    logistic = True, \n                    color = 'black',\n                    line_kws = {'lw' : 1, 'color' : 'red'},\n                    label = str(feature.replace('_', ' ').capitalize()))\n        ax.set_xlabel(str(feature.replace('_', ' ').capitalize()))\n        plt.ylabel('Probability')\n        plt.title('Logistic regression')\n        plt.legend()\n    \n        plt.tight_layout()\n        plt.show\n    \n    return None\n\nlogistic_regression_plot(worst_mean_se)\n\n\n# %% [markdown]\n# Hypothesis testing using Student's t-test.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-03-13T15:40:16.754978Z\",\"iopub.execute_input\":\"2023-03-13T15:40:16.755502Z\",\"iopub.status.idle\":\"2023-03-13T15:40:16.773363Z\",\"shell.execute_reply.started\":\"2023-03-13T15:40:16.755457Z\",\"shell.execute_reply\":\"2023-03-13T15:40:16.772100Z\"}}\n# Make a new dataframe with only the desired feature for t test  \nhypothesis_test_data = pd.DataFrame(data = data_df[['area_worst', 'diagnosis']])\nhypothesis_test_data = hypothesis_test_data.set_index(Diagnosis)\nt, p = stats.ttest_ind(hypothesis_test_data.loc[0], hypothesis_test_data.loc[1])\nprint(f'The t-value: {t}')\nprint(f'The p-value: {p}')\n\n\n\n        \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-03-13T15:40:21.158782Z\",\"iopub.execute_input\":\"2023-03-13T15:40:21.159412Z\",\"iopub.status.idle\":\"2023-03-13T15:40:21.178412Z\",\"shell.execute_reply.started\":\"2023-03-13T15:40:21.159378Z\",\"shell.execute_reply\":\"2023-03-13T15:40:21.176771Z\"}}\nclass Hypothesis_T_Test(object):\n    def __init__(self, feature, ind_variable = Diagnosis):\n        self.feature = feature\n        self.ind_variable = ind_variable\n        \n    def computeTandPValues(self):\n        hypothesis_test_data = pd.DataFrame(data = data_df[[self.feature, self.ind_variable]])\n        hypothesis_test_data = hypothesis_test_data.set_index(self.ind_variable)\n        self.variable_name = lambda : data_df[self.feature].name.replace('_', ' ').capitalize()\n        self.t_value, self.p_value = stats.ttest_ind(hypothesis_test_data.loc[0], hypothesis_test_data.loc[1])\n        print(f'Variable name: {self.variable_name()}: t-value: {self.t_value}, p-value: {self.p_value}')\n        \n        return self.t_value, self.p_value\n\nfor feature in worst_mean_se:\n    HTT = Hypothesis_T_Test(feature)\n    HTT.computeTandPValues()\n\n# %% [markdown]\n# Some correlation \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-03-13T15:40:31.663705Z\",\"iopub.execute_input\":\"2023-03-13T15:40:31.664169Z\",\"iopub.status.idle\":\"2023-03-13T15:40:31.685896Z\",\"shell.execute_reply.started\":\"2023-03-13T15:40:31.664132Z\",\"shell.execute_reply\":\"2023-03-13T15:40:31.684701Z\"}}\n# Create a correlation matrix\ncorr_matrix = input_data.corr().abs()\n# Select upper triangle of correlation matrix\nupper_triangular = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k = 1).astype(bool))\n# Find index of feature columns with correlation greater than 0.95\ncorrelation_threshold = 0.95\nfeatures_to_omit = [column for column in upper_triangular.columns if any(upper_triangular[column] > correlation_threshold)]\n# Remove features to omit \ncorrelation_data = input_data.drop(input_data[features_to_omit], axis = 1)\ncorrelation_data.columns\n\n\n# %% [markdown]\n# Machine learning\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-03-13T15:40:36.487190Z\",\"iopub.execute_input\":\"2023-03-13T15:40:36.487661Z\",\"iopub.status.idle\":\"2023-03-13T15:40:36.553130Z\",\"shell.execute_reply.started\":\"2023-03-13T15:40:36.487624Z\",\"shell.execute_reply\":\"2023-03-13T15:40:36.551282Z\"}}\nX = input_data\nY = data_df.diagnosis\n\nX_train, X_test, y_train, y_test = train_test_split(X, \n                                                    Y, \n                                                    test_size = 0.20, \n                                                    stratify = Y, \n                                                    random_state = 1234)\n#Robust feature scaling\nrs_object = RobustScaler()\nX_train = rs_object.fit_transform(X_train)\nX_test = rs_object.transform(X_test)\n\n# Define a function which trains a logistic model\ndef createModel(X_train, y_train):\n    \n    \n    LogitModel = LogisticRegression(solver = 'lbfgs', \n                             max_iter = 100, \n                             random_state = 1234)\n    \n    LogitModel.fit(X_train, y_train)  \n    \n    #Display model accuracy on the training data.\n    print(f'Accuracy for the training sample: {LogitModel.score(X_train, y_train):.2f}')\n    return LogitModel\n\n#Obtain the training results\nmodel = createModel(X_train, y_train)\n\n# %% [markdown]\n# Confusion matrix\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-03-13T15:40:44.249622Z\",\"iopub.execute_input\":\"2023-03-13T15:40:44.250035Z\",\"iopub.status.idle\":\"2023-03-13T15:40:44.528838Z\",\"shell.execute_reply.started\":\"2023-03-13T15:40:44.250002Z\",\"shell.execute_reply\":\"2023-03-13T15:40:44.527692Z\"}}\n\ncm = confusion_matrix(y_test, model.predict(X_test))\n \nTN = cm[0][0]\nTP = cm[1][1]\nFN = cm[1][0]\nFP = cm[0][1]\n \nprint(cm)\nprint(f'Accuracy on the test data: {(TP + TN) / (TP + TN + FN + FP): .2f}')\nprint()# Print a new line\n\ndef displayConfusionMatrix():\n    disp = ConfusionMatrixDisplay(confusion_matrix = cm,\n                                  display_labels = model.classes_)\n    \n    disp.plot()\n    plt.grid(visible = False)\n    plt.title('Confusion matrix')\n    plt.show()\n\ndisplayConfusionMatrix()\n\n# %% [markdown]\n# Classification report is used in machine learning to compute accuracy of a classification model from the values of the confusion matrix. In the classification report, precision is a measure of positive predictions.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-03-13T15:41:18.512394Z\",\"iopub.execute_input\":\"2023-03-13T15:41:18.513866Z\",\"iopub.status.idle\":\"2023-03-13T15:41:18.527316Z\",\"shell.execute_reply.started\":\"2023-03-13T15:41:18.513811Z\",\"shell.execute_reply\":\"2023-03-13T15:41:18.526070Z\"}}\n\nprint(f'Logistic regression model ')\n#Check precision, recall, f1-score\nprint(f'Classification report')\nprint(classification_report(y_test, model.predict(X_test)))\n#Another way to get the models accuracy on the test data\nprint(f'Accuracy score {accuracy_score(y_test, model.predict(X_test)):.4f}')\nprint() #Print a new line\n\n# %% [markdown]\n# ROC Curve\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-03-13T15:41:22.392480Z\",\"iopub.execute_input\":\"2023-03-13T15:41:22.392885Z\",\"iopub.status.idle\":\"2023-03-13T15:41:22.691284Z\",\"shell.execute_reply.started\":\"2023-03-13T15:41:22.392851Z\",\"shell.execute_reply\":\"2023-03-13T15:41:22.690098Z\"}}\n# Compute predicted probabilities and keep results only for positive outcome \ny_pred_prob = model.predict_proba(X_test)[:,1]\n# Generate ROC curve values and capture only fpr, and tpr, but not thresholds\nfpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n\nprint(f'The AUC score for the logistic regression model is: {auc(fpr, tpr):.4f}')\n\ndef createROC():\n    fig = plt.figure()\n    ax = fig.add_subplot()\n\n    plt.plot([0, 1], [0, 1], 'k-.', label = 'Random prediction')\n    plt.plot(fpr, tpr, label = 'Logistic regression model: AUC = %0.4f' % auc(fpr, tpr))\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve for Logistic Regression')\n\n    ax.grid(False)\n    plt.legend()\n    plt.show()\n\ncreateROC()\n\n# %% [markdown]\n# ","metadata":{"_uuid":"ab776a02-4b71-45ba-a105-7bf13cd33df0","_cell_guid":"23cedf88-093e-4bd4-8a3f-963c598dcb95","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}